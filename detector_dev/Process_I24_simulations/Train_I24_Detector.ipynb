{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries for detection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import Detectors.Deep_Learning.AutoEncoders.utils\n",
    "reload(Detectors.Deep_Learning.AutoEncoders.utils)\n",
    "\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import SeqDataset,train_epoch,eval_data,train_model,get_cnn_lstm_ae_model,make_train_X,sliding_window_mult_feat\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import get_loss_filter_indiv as loss_smooth\n",
    "from Detectors.Deep_Learning.AutoEncoders.cnn_lstm_ae import CNNRecurrentAutoencoder\n",
    "\n",
    "\n",
    "import flow.visualize.visualize_ring as visualize_ring\n",
    "from flow.visualize.visualize_ring import get_measured_leader,get_rel_dist_to_measured_leader,get_vel_of_measured_leader\n",
    "\n",
    "\n",
    "import Detectors.Deep_Learning.AutoEncoders.utils\n",
    "reload(Detectors.Deep_Learning.AutoEncoders.utils)\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import SeqDataset,train_epoch,eval_data,train_model\n",
    "\n",
    "import torch\n",
    "\n",
    "# Anti-Flow specific functions for  detection:\n",
    "\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import sliding_window\n",
    "from Detectors.Deep_Learning.AutoEncoders.cnn_lstm_ae import CNNRecurrentAutoencoder\n",
    "\n",
    "model = get_cnn_lstm_ae_model(n_features=4)\n",
    "\n",
    "print('Loaded libraries for detection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_i24_model(timeseries_dict,n_epoch=300,model=None,seq_len=100):\n",
    "    veh_ids = list(timeseries_dict.keys())\n",
    "    timeseries_list = []\n",
    "\n",
    "    for veh_id in veh_ids:\n",
    "        #[time,speed,headway,accel,leader_speed,fuel_consumption]\n",
    "        num_samples = len(timeseries_dict[veh_id][:,0])\n",
    "        if(num_samples > seq_len):\n",
    "            speed = timeseries_dict[veh_id][:,1]\n",
    "            accel = np.gradient(speed,.1)\n",
    "            head_way = timeseries_dict[veh_id][:,2]\n",
    "            rel_vel = timeseries_dict[veh_id][:,3]\n",
    "            \n",
    "#             for i in range(len(head_way)):\n",
    "#                 if(head_way[i] > 200.0):\n",
    "#                     head_way[i] = 200.0\n",
    "#                     rel_vel[i] = 0.0\n",
    "\n",
    "            timeseries_list.append([speed,accel,head_way,rel_vel])\n",
    "        \n",
    "    train_X = make_train_X(timeseries_list,seq_len=seq_len)\n",
    "    \n",
    "    if(model is None):\n",
    "        model = get_cnn_lstm_ae_model(n_features=4,seq_len=seq_len)\n",
    "    \n",
    "    model_file_name = 'i24_detector_no_position_seq_len_'+str(seq_len)\n",
    "    \n",
    "    print('Beginning training...')\n",
    "    begin_time = time.time()\n",
    "    model = train_model(model,train_X,model_file_name,n_epoch=n_epoch,seq_len=seq_len)\n",
    "    finish_time = time.time()\n",
    "    print('Finished training, total time: '+str(finish_time-begin_time))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training procedure defined.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "def get_sim_timeseries(csv_path,warmup_period=0.0):\n",
    "    row_num = 1\n",
    "    curr_veh_id = 'id'\n",
    "    sim_dict = {}\n",
    "    curr_veh_data = []\n",
    "\n",
    "    id_index = 0\n",
    "    time_index = 0\n",
    "    speed_index = 0\n",
    "    headway_index = 0\n",
    "    relvel_index = 0\n",
    "    edge_index = 0\n",
    "    x_index = 0\n",
    "    y_index = 0\n",
    "    position_index = 0\n",
    "\n",
    "\n",
    "\n",
    "    edge_list = ['Eastbound_3',':202186118','Eastbound_4','Eastbound_5','Eastbound_6',':202186134','Eastbound_7',':202236780','Eastbound_8']\n",
    "\n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        row1 = next(csvreader)\n",
    "        num_entries = len(row1)\n",
    "        while(row1[id_index]!='id' and id_index<num_entries):id_index +=1\n",
    "        while(row1[edge_index]!='edge_id' and edge_index<num_entries):edge_index +=1\n",
    "        while(row1[time_index]!='time' and time_index<num_entries):time_index +=1\n",
    "        while(row1[speed_index]!='speed' and speed_index<num_entries):speed_index +=1\n",
    "        while(row1[headway_index]!='headway' and headway_index<num_entries):headway_index +=1\n",
    "        while(row1[relvel_index]!='leader_rel_speed' and relvel_index<num_entries):relvel_index +=1\n",
    "        while(row1[x_index]!='x' and x_index<num_entries):x_index +=1\n",
    "        while(row1[y_index]!='y' and y_index<num_entries):y_index +=1\n",
    "        while(row1[position_index]!='relative_position' and position_index<num_entries):position_index +=1\n",
    "\n",
    "\n",
    "        for row in csvreader:\n",
    "            if(row_num > 1):\n",
    "                # Don't read header\n",
    "                if(curr_veh_id != row[id_index]):\n",
    "                    #Add in new data to the dictionary:\n",
    "\n",
    "                    #Store old data:\n",
    "                    if(len(curr_veh_data)>0):\n",
    "                        sim_dict[curr_veh_id] = np.array(curr_veh_data).astype(float)\n",
    "                        sys.stdout.write('\\r'+'Veh id: '+curr_veh_id+ ' row: ' +str(row_num)+'\\r')\n",
    "                    #Rest where data is being stashed:\n",
    "                    curr_veh_data = []\n",
    "                    curr_veh_id = row[id_index] # Set new veh id\n",
    "                    #Allocate space for storing:\n",
    "\n",
    "                curr_veh_id = row[id_index]\n",
    "                time = float(row[time_index])\n",
    "                edge = row[edge_index]\n",
    "                \n",
    "                \n",
    "                if(time > warmup_period and edge in edge_list):\n",
    "                    # data = [time,speed,headway,leader_rel_speed,x,y]\n",
    "                    if(edge == 'Eastbound_8'):\n",
    "                        position = float(row[position_index])\n",
    "                        if(position < 250):\n",
    "                            data = [row[time_index],row[speed_index],row[headway_index],row[relvel_index],row[x_index],row[y_index]]\n",
    "                            curr_veh_data.append(data)\n",
    "                    else:\n",
    "                        data = [row[time_index],row[speed_index],row[headway_index],row[relvel_index],row[x_index],row[y_index]]\n",
    "                        curr_veh_data.append(data)\n",
    "                    \n",
    "            row_num += 1\n",
    "\n",
    "        #Add the very last vehicle's information:\n",
    "        sim_dict[curr_veh_id] = np.array(curr_veh_data).astype(float)\n",
    "        print('Data loaded.')\n",
    "    return sim_dict\n",
    "\n",
    "def train_i24_model(timeseries_dict,n_epoch=300,model=None,seq_len=100):\n",
    "    veh_ids = list(timeseries_dict.keys())\n",
    "    timeseries_list = []\n",
    "\n",
    "    for veh_id in veh_ids:\n",
    "        #[time,speed,headway,accel,leader_speed,fuel_consumption]\n",
    "        num_samples = len(timeseries_dict[veh_id][:,0])\n",
    "        if(num_samples > seq_len):\n",
    "            speed = timeseries_dict[veh_id][:,1]\n",
    "            accel = np.gradient(speed,.1)\n",
    "            head_way = timeseries_dict[veh_id][:,2]\n",
    "            rel_vel = timeseries_dict[veh_id][:,3]\n",
    "            \n",
    "            for i in range(len(head_way)):\n",
    "                if(head_way[i] > 200.0):\n",
    "                    head_way[i] = 200.0\n",
    "                    rel_vel[i] = 0.0\n",
    "\n",
    "            timeseries_list.append([speed,accel,head_way,rel_vel])\n",
    "        \n",
    "    train_X = make_train_X(timeseries_list,seq_len=seq_len)\n",
    "    \n",
    "    if(model is None):\n",
    "        model = get_cnn_lstm_ae_model(n_features=4,seq_len=seq_len)\n",
    "    \n",
    "    model_file_name = 'i24_detector_no_position_seq_len_'+str(seq_len)\n",
    "    \n",
    "    print('Beginning training...')\n",
    "    begin_time = time.time()\n",
    "    model = train_model(model,train_X,model_file_name,n_epoch=n_epoch,seq_len=seq_len)\n",
    "    finish_time = time.time()\n",
    "    print('Finished training, total time: '+str(finish_time-begin_time))\n",
    "\n",
    "    return model\n",
    "    \n",
    "print('Training procedure defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded._60.647 row: 4714684\n",
      "Total loading time: 28.800753116607666\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "csv_path = '/Volumes/Backup/George_Research/benign_initial_i24/1800_inflow_0.2_ACC.csv'\n",
    "warmup_period = 1200.0\n",
    "\n",
    "begin_load_time = time.time()\n",
    "timeseries_dict = get_sim_timeseries(csv_path,warmup_period)\n",
    "end_load_time = time.time()\n",
    "\n",
    "print('Total loading time: '+str(end_load_time-begin_load_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "flow_70.617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fabdb6fa2b0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "veh_ids = list(timeseries_dict.keys())\n",
    "print(len(veh_ids))\n",
    "veh_id = veh_ids[1400]\n",
    "print(veh_id)\n",
    "# print(timeseries_dict[veh_id])\n",
    "plt.plot(timeseries_dict[veh_id][:,0],timeseries_dict[veh_id][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Creating new model.\n",
      "Best loss 710.344416838681\n",
      "Beginning training.\n",
      "Number epochs: 0 epoch step time: 119.63578295707703\n",
      "Epoch 0, total loss 3413720.215393, total predictions 14950, avg loss 228.342489 2022-06-17 14:35:10.170859\n",
      "Saving model. Best loss: 228.34248932395093\n",
      "Number epochs: 1 epoch step time: 119.08268976211548\n",
      "Number epochs: 2 epoch step time: 122.2138147354126\n",
      "Number epochs: 3 epoch step time: 122.22184991836548\n",
      "Number epochs: 4 epoch step time: 128.5994110107422\n",
      "Saving model. Best loss: 194.3318977258995\n",
      "Number epochs: 5 epoch step time: 131.90479397773743\n",
      "Epoch 5, total loss 2286284.727661, total predictions 14950, avg loss 152.928744 2022-06-17 14:45:34.194144\n",
      "Saving model. Best loss: 152.92874432515939\n",
      "Number epochs: 6 epoch step time: 136.3772578239441\n",
      "Saving model. Best loss: 146.7385672007277\n",
      "Number epochs: 7 epoch step time: 134.05749893188477\n",
      "Saving model. Best loss: 130.7468530416329\n",
      "Number epochs: 8 epoch step time: 130.87732887268066\n",
      "Number epochs: 9 epoch step time: 137.55480313301086\n",
      "Number epochs: 10 epoch step time: 129.95288014411926\n",
      "Epoch 10, total loss 1777718.370483, total predictions 14950, avg loss 118.910928 2022-06-17 14:56:43.014636\n",
      "Saving model. Best loss: 118.91092779153166\n",
      "Number epochs: 11 epoch step time: 128.9973440170288\n",
      "Saving model. Best loss: 117.4990465420624\n",
      "Number epochs: 12 epoch step time: 131.8607349395752\n",
      "Number epochs: 13 epoch step time: 131.86603474617004\n",
      "Saving model. Best loss: 117.430366827413\n",
      "Number epochs: 14 epoch step time: 129.1082248687744\n",
      "Saving model. Best loss: 114.86057532677283\n",
      "Number epochs: 15 epoch step time: 129.0015687942505\n",
      "Epoch 15, total loss 2143041.911652, total predictions 14950, avg loss 143.347285 2022-06-17 15:07:33.849374\n",
      "Number epochs: 16 epoch step time: 126.938472032547\n",
      "Saving model. Best loss: 112.94793551748015\n",
      "Number epochs: 17 epoch step time: 126.51369500160217\n",
      "Number epochs: 18 epoch step time: 127.5615770816803\n",
      "Number epochs: 19 epoch step time: 128.49605464935303\n",
      "Number epochs: 20 epoch step time: 126.58057808876038\n",
      "Epoch 20, total loss 1849688.711151, total predictions 14950, avg loss 123.724997 2022-06-17 15:18:09.940410\n",
      "Number epochs: 21 epoch step time: 125.83409309387207\n",
      "Number epochs: 22 epoch step time: 123.36337995529175\n",
      "Number epochs: 23 epoch step time: 123.84002470970154\n",
      "Number epochs: 24 epoch step time: 123.2940821647644\n",
      "Number epochs: 25 epoch step time: 126.90355110168457\n",
      "Epoch 25, total loss 1647614.091644, total predictions 14950, avg loss 110.208300 2022-06-17 15:28:33.176234\n",
      "Saving model. Best loss: 110.20830044443392\n",
      "Number epochs: 26 epoch step time: 127.46285891532898\n",
      "Saving model. Best loss: 105.5846041737432\n",
      "Number epochs: 27 epoch step time: 133.2279918193817\n",
      "Number epochs: 28 epoch step time: 131.36629104614258\n",
      "Saving model. Best loss: 95.61859111364869\n",
      "Number epochs: 29 epoch step time: 132.54175996780396\n",
      "Saving model. Best loss: 91.58681372703118\n",
      "Number epochs: 30 epoch step time: 146.59204411506653\n",
      "Epoch 30, total loss 1468635.184906, total predictions 14950, avg loss 98.236467 2022-06-17 15:39:44.367947\n",
      "Number epochs: 31 epoch step time: 137.88705492019653\n",
      "Number epochs: 32 epoch step time: 129.1097869873047\n",
      "Saving model. Best loss: 86.86720072564472\n",
      "Number epochs: 33 epoch step time: 148.1023178100586\n",
      "Number epochs: 34 epoch step time: 141.07472896575928\n",
      "Number epochs: 35 epoch step time: 123.7459237575531\n",
      "Epoch 35, total loss 1267948.008560, total predictions 14950, avg loss 84.812576 2022-06-17 15:51:04.288355\n",
      "Saving model. Best loss: 84.81257582342346\n",
      "Number epochs: 36 epoch step time: 123.28928089141846\n",
      "Number epochs: 37 epoch step time: 123.4620418548584\n",
      "Number epochs: 38 epoch step time: 120.61153483390808\n",
      "Number epochs: 39 epoch step time: 121.41793727874756\n",
      "Saving model. Best loss: 83.8416634274486\n",
      "Finished training.\n",
      "Finished training, total time: 5195.359653234482\n"
     ]
    }
   ],
   "source": [
    "seq_len = 200\n",
    "\n",
    "i24_detection_model = train_i24_model(timeseries_dict,n_epoch=40,model=None,seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Loaded existing model: /Users/vanderbilt/Desktop/Research_2022/Anti-Flow/detector_dev/models/cnn_lstm_ae_i24_detector_no_position_seq_len_200.pt\n",
      "Best loss 83.92865857995075\n",
      "Beginning training.\n",
      "Number epochs: 0 epoch step time: 121.05891990661621\n",
      "Epoch 0, total loss 1395382.113876, total predictions 14950, avg loss 93.336596 2022-06-17 16:03:18.309215\n",
      "Number epochs: 1 epoch step time: 123.54077291488647\n",
      "Saving model. Best loss: 72.17000126459128\n",
      "Number epochs: 2 epoch step time: 125.13610315322876\n",
      "Number epochs: 3 epoch step time: 124.8598039150238\n",
      "Number epochs: 4 epoch step time: 123.5720808506012\n",
      "Number epochs: 5 epoch step time: 124.24039602279663\n",
      "Epoch 5, total loss 1101235.787781, total predictions 14950, avg loss 73.661257 2022-06-17 16:13:39.659035\n",
      "Number epochs: 6 epoch step time: 121.11639285087585\n",
      "Number epochs: 7 epoch step time: 128.75385904312134\n",
      "Number epochs: 8 epoch step time: 146.18097019195557\n",
      "Number epochs: 9 epoch step time: 125.82891702651978\n",
      "Number epochs: 10 epoch step time: 127.32308411598206\n",
      "Epoch 10, total loss 1600494.841217, total predictions 14950, avg loss 107.056511 2022-06-17 16:24:28.862951\n",
      "Number epochs: 11 epoch step time: 127.24091506004333\n",
      "Number epochs: 12 epoch step time: 126.90063691139221\n",
      "Number epochs: 13 epoch step time: 126.80925297737122\n",
      "Number epochs: 14 epoch step time: 128.3080291748047\n",
      "Number epochs: 15 epoch step time: 125.8816967010498\n",
      "Epoch 15, total loss 1188091.280746, total predictions 14950, avg loss 79.470989 2022-06-17 16:35:04.004148\n",
      "Number epochs: 16 epoch step time: 125.23943185806274\n",
      "Number epochs: 17 epoch step time: 140.92908120155334\n",
      "Number epochs: 18 epoch step time: 142.4686369895935\n",
      "Saving model. Best loss: 69.35322379121813\n",
      "Number epochs: 19 epoch step time: 141.8366138935089\n",
      "Finished training.\n",
      "Finished training, total time: 2613.4307770729065\n"
     ]
    }
   ],
   "source": [
    "i24_detection_model = train_i24_model(timeseries_dict,n_epoch=20,model=None,seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined functions for doing anomaly detection.\n"
     ]
    }
   ],
   "source": [
    "import flow.visualize.visualize_ring as visualize_ring\n",
    "reload(visualize_ring)\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from time import time as timer_start\n",
    "\n",
    "def get_data_for_AE(timeseries_dict,veh_id):\n",
    "    timeseries_data = timeseries_dict[veh_id]\n",
    "    speed = timeseries_dict[veh_id][:,1]\n",
    "    speed_smoothed = savgol_filter(speed,21,3)\n",
    "    accel = np.gradient(speed_smoothed,.1)\n",
    "    head_way = timeseries_dict[veh_id][:,2]\n",
    "    rel_vel = timeseries_dict[veh_id][:,3]\n",
    "    timeseries_data_list = [speed,accel,head_way,rel_vel]\n",
    "\n",
    "    return timeseries_data_list\n",
    "\n",
    "\n",
    "def get_losses_complete_obs(timeseries_dict,model,seq_len=200,warmup_period=1200):\n",
    "\n",
    "    begin_time = time.time()\n",
    "\n",
    "    veh_ids = list(timeseries_dict.keys())\n",
    "   \n",
    "    num_veh_processed = 0\n",
    "    \n",
    "    total_vehicles = len(veh_ids)\n",
    "\n",
    "    testing_losses_dict = {}\n",
    "\n",
    "    for veh_id in veh_ids:\n",
    "        \n",
    "        speed = timeseries_dict[veh_id][:,1]\n",
    "        \n",
    "        if(len(speed) > seq_len):\n",
    "#             accel = np.gradient(speed,.1)\n",
    "#             head_way = timeseries_dict[veh_id][:,2]\n",
    "#             rel_vel = timeseries_dict[veh_id][:,3]\n",
    "\n",
    "            timeseries_list = get_data_for_AE(timeseries_dict,veh_id)\n",
    "\n",
    "            _,loss = sliding_window_mult_feat(model,timeseries_list,seq_len=seq_len)\n",
    "\n",
    "            testing_losses_dict[veh_id]=loss\n",
    "\n",
    "        num_veh_processed+=1\n",
    "\n",
    "        if(num_veh_processed % 100 == 0):\n",
    "            total_compute_time = time.time()-begin_time\n",
    "            sys.stdout.write('\\r'+'Vehicles processed: '+str(num_veh_processed)+'/'+str(total_vehicles)+', total compute time: '+str(total_compute_time)+'\\r')\n",
    "        \n",
    "    print('\\n')\n",
    "    \n",
    "    smoothed_losses = {}\n",
    "    \n",
    "    #Get smoothed loss values:\n",
    "    \n",
    "    for veh_id in testing_losses_dict:\n",
    "        loss = testing_losses_dict[veh_id]\n",
    "        if(loss is not None):\n",
    "            vehicles_time = timeseries_dict[veh_id][:,0]\n",
    "            smoothed_losses[veh_id] =  [vehicles_time,loss_smooth(vehicles_time,loss)]\n",
    "    \n",
    "    print('Total time to calculate loses: '+str(time.time()-begin_time))\n",
    "    \n",
    "    return smoothed_losses\n",
    "\n",
    "print('Defined functions for doing anomaly detection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded._110.631 row: 6727804\n"
     ]
    }
   ],
   "source": [
    "# emission_path = '/Volumes/Backup/George_Research/i24_random_sample/part 1/Dur_9.717839924656609_Mag_-1.4249530669819752_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1.csv'\n",
    "\n",
    "emission_path = '/Users/vanderbilt/Desktop/Research_2022/Anti-Flow/detector_dev/data/Dur_45_Mag_-1.0_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1.csv'\n",
    "\n",
    "timeseries_dict = get_sim_timeseries(csv_path=emission_path,warmup_period=warmup_period)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicles processed: 1500/1578, total compute time: 5564.3638088703165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanderbilt/Desktop/Research_2022/Anti-Flow/Detectors/Deep_Learning/AutoEncoders/utils.py:196: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veh_losses_filtered = np.divide(veh_losses_filtered,loss_counts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to calculate loses: 5593.666415929794\n",
      "Total time: 5593.668439149857\n"
     ]
    }
   ],
   "source": [
    "model = get_cnn_lstm_ae_model(n_features=4,seq_len=200)\n",
    "# Load in a trained model:\n",
    "MODEL_PATH = os.path.join(os.getcwd(),'models/cnn_lstm_ae_i24_detector_no_position_seq_len_200.pt')\n",
    "model.load_state_dict(torch.load(MODEL_PATH,map_location=torch.device('cpu')))\n",
    "\n",
    "begin_time = time.time()\n",
    "\n",
    "i24_losses_test = get_losses_complete_obs(timeseries_dict,model,seq_len=200,warmup_period=warmup_period)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('Total time: '+str(end_time-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss file written to csv.\n"
     ]
    }
   ],
   "source": [
    "def write_losses_to_file(smoothed_losses,file_name):\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for veh_id in smoothed_losses:\n",
    "            vehicle_times = smoothed_losses[veh_id][0]\n",
    "            losses = smoothed_losses[veh_id][1]\n",
    "            num_samples = len(losses)\n",
    "            for i in range(num_samples):\n",
    "                writer.writerow([veh_id,vehicle_times[i],losses[i]])\n",
    "                \n",
    "            \n",
    "    print('Loss file written to csv.')\n",
    "\n",
    "def get_sim_name(file_name):\n",
    "    i = 0\n",
    "    while(file_name[i:i+3] != 'Dur'):i+=1\n",
    "    return file_name[i:]\n",
    "\n",
    "file_name = 'Dur_45_Mag_-1.0_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1_losses_200seqlen.csv'\n",
    "\n",
    "write_losses_to_file(i24_losses_test,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined function.\n"
     ]
    }
   ],
   "source": [
    "def get_sim_timeseries_all_data_i24(csv_path,warmup_period=0.0):\n",
    "    row_num = 1\n",
    "    curr_veh_id = 'id'\n",
    "    sim_dict = {}\n",
    "    curr_veh_data = []\n",
    "\n",
    "    id_index = 0\n",
    "    time_index = 0\n",
    "    speed_index = 0\n",
    "    headway_index = 0\n",
    "    relvel_index = 0\n",
    "    edge_index = 0\n",
    "    x_index = 0\n",
    "    y_index = 0\n",
    "    position_index = 0\n",
    "    \n",
    "    edge_list = ['Eastbound_3',':202186118','Eastbound_4','Eastbound_5','Eastbound_6',':202186134','Eastbound_7',':202236780','Eastbound_8']\n",
    "\n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        row1 = next(csvreader)\n",
    "        num_entries = len(row1)\n",
    "        while(row1[id_index]!='id' and id_index<num_entries):id_index +=1\n",
    "        while(row1[edge_index]!='edge_id' and edge_index<num_entries):edge_index +=1\n",
    "        while(row1[time_index]!='time' and time_index<num_entries):time_index +=1\n",
    "        while(row1[speed_index]!='speed' and speed_index<num_entries):speed_index +=1\n",
    "        while(row1[headway_index]!='headway' and headway_index<num_entries):headway_index +=1\n",
    "        while(row1[relvel_index]!='leader_rel_speed' and relvel_index<num_entries):relvel_index +=1\n",
    "        while(row1[x_index]!='x' and x_index<num_entries):x_index +=1\n",
    "        while(row1[y_index]!='y' and y_index<num_entries):y_index +=1\n",
    "        while(row1[position_index]!='relative_position' and position_index<num_entries):position_index +=1\n",
    "\n",
    "\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        id_index = 0\n",
    "        time_index = 0\n",
    "        row1 = next(csvreader)\n",
    "        while(row1[id_index]!='id' and id_index<num_entries):id_index +=1\n",
    "        while(row1[time_index]!='time' and time_index<num_entries):time_index +=1\n",
    "\n",
    "        row_num += 1\n",
    "\n",
    "        for row in csvreader:\n",
    "            if(row_num > 1):\n",
    "                # Don't read header\n",
    "                if(curr_veh_id != row[curr_veh_id]):\n",
    "                    #Add in new data to the dictionary:\n",
    "\n",
    "                    #Store old data:\n",
    "                    if(len(curr_veh_data)>0):\n",
    "                        sim_dict[curr_veh_id] = curr_veh_data\n",
    "                    #Rest where data is being stashed:\n",
    "                    curr_veh_data = []\n",
    "                    curr_veh_id = row[curr_veh_id] # Set new veh id\n",
    "                    #Allocate space for storing:\n",
    "                    sim_dict[curr_veh_id] = []\n",
    "\n",
    "                curr_veh_id = row[curr_veh_id]\n",
    "                time = float(row[0])\n",
    "                if(time > warmup_period):\n",
    "                    # data = [time,speed,headway,leader_rel_speed]\n",
    "                    curr_veh_data.append(row)\n",
    "            row_num += 1\n",
    "\n",
    "        #Add the very last vehicle's information:\n",
    "        sim_dict[curr_veh_id] = curr_veh_data\n",
    "        print('Data loaded.')\n",
    "    return sim_dict\n",
    "\n",
    "print('Defined function.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bd16b5e32e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcsv_path_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/vanderbilt/Desktop/Research_2022/Anti-Flow/detector_dev/data/Dur_45_Mag_-1.0_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_sim_data_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sim_timeseries_all_data_i24\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_path_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-3e80d9f4c38e>\u001b[0m in \u001b[0;36mget_sim_timeseries_all_data_i24\u001b[0;34m(csv_path, warmup_period)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtime_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mrow1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mid_index\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mid_index\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'time'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime_index\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime_index\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "csv_path_attack = '/Users/vanderbilt/Desktop/Research_2022/Anti-Flow/detector_dev/data/Dur_45_Mag_-1.0_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1.csv'\n",
    "\n",
    "all_sim_data_attack = get_sim_timeseries_all_data_i24(csv_path = csv_path_attack, warmup_period = warmup_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss_dict(file_name):\n",
    "    loss_dict = {}\n",
    "    with open(file_name, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        \n",
    "        row = next(reader)\n",
    "        curr_id = row[0]\n",
    "        curr_losses = [row[2]]\n",
    "        \n",
    "        for row in reader:\n",
    "            if(curr_id != row[0]):\n",
    "                loss_dict[curr_id] = np.array(curr_losses).astype(float)\n",
    "                curr_losses = []\n",
    "                curr_id = row[0]\n",
    "            \n",
    "            curr_losses.append(row[2])\n",
    "            \n",
    "    return loss_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, total time: 26.687623977661133\n",
      "Vehicles processed: 300/377, time per step: 3.5940893939659664\n",
      "\n",
      "Total time to calculate loses: 92.13576078414917\n",
      "Loss file written to csv.\n",
      "Total processing time: 92.36598706245422\n"
     ]
    }
   ],
   "source": [
    "def process_file_for_losses(emission_file_path,loss_emission_repo,model,warmup_period=1200):\n",
    "    i24_losses_test = get_losses_complete_obs(emission_file_path,model,warmup_period=warmup_period)\n",
    "    sim_name = get_sim_name(emission_file_path)\n",
    "    file_path_to_write = os.path.join(loss_emission_repo,sim_name)\n",
    "    write_losses_to_file(i24_losses_test,file_path_to_write)\n",
    "    return file_path_to_write\n",
    "    \n",
    "    \n",
    "# loss_emission_repo = '/Volumes/Backup/George_Research/i24_random_sample/part 1/losses/'    \n",
    "    \n",
    "# emission_file_path = '/Volumes/Backup/George_Research/i24_random_sample/part 1/Dur_9.717839924656609_Mag_-1.4249530669819752_Inflow_1800_ACCPenetration_0.2_AttackPenetration_0.1_ver_1.csv'\n",
    "\n",
    "# begin_time = time.time()\n",
    "# process_file_for_losses(emission_file_path,loss_emission_repo,i24_detection_model_retrained,warmup_period=1780)\n",
    "# end_time = time.time()\n",
    "# print('Total processing time: '+str(end_time-begin_time))\n",
    "\n",
    "# write_losses_to_file(i24_losses_test,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with detector that has positional knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training procedure defined.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import Detectors.Deep_Learning.AutoEncoders.utils\n",
    "reload(Detectors.Deep_Learning.AutoEncoders.utils)\n",
    "\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import SeqDataset,train_epoch,eval_data,train_model,get_cnn_lstm_ae_model,make_train_X,sliding_window_mult_feat\n",
    "from Detectors.Deep_Learning.AutoEncoders.utils import get_loss_filter_indiv as loss_smooth\n",
    "from Detectors.Deep_Learning.AutoEncoders.cnn_lstm_ae import CNNRecurrentAutoencoder\n",
    "\n",
    "\n",
    "def get_sim_timeseries(csv_path,warmup_period=0.0):\n",
    "    row_num = 1\n",
    "    curr_veh_id = 'id'\n",
    "    sim_dict = {}\n",
    "    curr_veh_data = []\n",
    "    \n",
    "    edge_list = ['Eastbound_3','Eastbound_4','Eastbound_5','Eastbound_6','Eastbound_7']\n",
    "\n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in csvreader:\n",
    "            if(row_num > 1):\n",
    "                # Don't read header\n",
    "                if(curr_veh_id != row[1]):\n",
    "                    #Add in new data to the dictionary:\n",
    "\n",
    "                    #Store old data:\n",
    "                    if(len(curr_veh_data)>0):\n",
    "                        sim_dict[curr_veh_id] = np.array(curr_veh_data).astype(float)\n",
    "                        sys.stdout.write('\\r'+'Veh id: '+curr_veh_id+ ' row: ' +str(row_num)+'\\r')\n",
    "                    #Rest where data is being stashed:\n",
    "                    curr_veh_data = []\n",
    "                    curr_veh_id = row[1] # Set new veh id\n",
    "                    #Allocate space for storing:\n",
    "#                     sim_dict[curr_veh_id] = []\n",
    "\n",
    "                curr_veh_id = row[1]\n",
    "                time = float(row[0])\n",
    "                edge = row[-4]\n",
    "                if(time > warmup_period and edge in edge_list):\n",
    "                    # data = [time,speed,headway,leader_rel_speed,x,y]\n",
    "                    data = [row[0],row[4],row[5],row[8],row[2],row[3]]\n",
    "                    curr_veh_data.append(data)\n",
    "            row_num += 1\n",
    "\n",
    "        #Add the very last vehicle's information:\n",
    "        sim_dict[curr_veh_id] = np.array(curr_veh_data).astype(float)\n",
    "        print('Data loaded.')\n",
    "    return sim_dict\n",
    "\n",
    "\n",
    "def train_i24_model(timeseries_dict,n_epoch=60,model=None,seq_len=200):\n",
    "    veh_ids = list(timeseries_dict.keys())\n",
    "    timeseries_list = []\n",
    "    \n",
    "    \n",
    "    x_origin = 5800\n",
    "    y_origin = 21350\n",
    "\n",
    "    for veh_id in veh_ids:\n",
    "        #[time,speed,headway,accel,leader_speed,fuel_consumption]\n",
    "        num_samples = len(timeseries_dict[veh_id][:,0])\n",
    "        if(num_samples > seq_len):\n",
    "            speed = timeseries_dict[veh_id][:,1]\n",
    "            accel = np.gradient(speed,.1)\n",
    "            head_way = timeseries_dict[veh_id][:,2]\n",
    "            rel_vel = timeseries_dict[veh_id][:,3]\n",
    "            x_vals = timeseries_dict[veh_id][:,4] - x_origin\n",
    "            y_vals = timeseries_dict[veh_id][:,5] - y_origin\n",
    "\n",
    "            timeseries_list.append([speed,accel,head_way,rel_vel,x_vals,y_vals])\n",
    "        \n",
    "    train_X = make_train_X(timeseries_list,seq_len=seq_len)\n",
    "    \n",
    "    if(model is None):\n",
    "        model = get_cnn_lstm_ae_model(n_features=6,seq_len=seq_len)\n",
    "    \n",
    "    model_file_name = 'i24_detector_complete_obs_positional'\n",
    "    \n",
    "    print('Beginning training...')\n",
    "    begin_time = time.time()\n",
    "    model = train_model(model,train_X,model_file_name,n_epoch=n_epoch,seq_len=seq_len)\n",
    "    finish_time = time.time()\n",
    "    print('Finished training, total time: '+str(finish_time-begin_time))\n",
    "\n",
    "    return model\n",
    "    \n",
    "print('Training procedure defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded._60.647 row: 4714685\n"
     ]
    }
   ],
   "source": [
    "training_file_path = '/Volumes/Backup/George_Research/benign_initial_i24/1800_inflow_0.2_ACC.csv'\n",
    "warump_period = 1200.0\n",
    "timeseries_dict_training = get_sim_timeseries(csv_path=training_file_path,\n",
    "                                              warmup_period=warump_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Creating new model.\n",
      "Best loss 18689.24545679209\n",
      "Beginning training.\n",
      "Number epochs: 0 epoch step time: 139.00355005264282\n",
      "Epoch 0, total loss 256231443.878906, total predictions 14700, avg loss 17430.710468 2022-06-16 13:05:12.698260\n",
      "Saving model. Best loss: 17430.710467952806\n",
      "Number epochs: 1 epoch step time: 146.45975494384766\n",
      "Saving model. Best loss: 16310.174010948129\n",
      "Number epochs: 2 epoch step time: 144.49372029304504\n",
      "Saving model. Best loss: 15244.240525616497\n",
      "Number epochs: 3 epoch step time: 151.89895510673523\n",
      "Saving model. Best loss: 14257.464796981292\n",
      "Number epochs: 4 epoch step time: 136.01705408096313\n",
      "Saving model. Best loss: 13366.590214445154\n",
      "Number epochs: 5 epoch step time: 134.78955793380737\n",
      "Epoch 5, total loss 184811990.019531, total predictions 14700, avg loss 12572.244219 2022-06-16 13:17:06.358804\n",
      "Saving model. Best loss: 12572.24421901573\n",
      "Number epochs: 6 epoch step time: 128.93833899497986\n",
      "Saving model. Best loss: 11868.471113148384\n",
      "Number epochs: 7 epoch step time: 127.78834915161133\n",
      "Saving model. Best loss: 11247.78666135204\n",
      "Number epochs: 8 epoch step time: 126.55454277992249\n",
      "Saving model. Best loss: 10702.473541400936\n",
      "Number epochs: 9 epoch step time: 124.12588119506836\n",
      "Saving model. Best loss: 10225.10721646471\n",
      "Number epochs: 10 epoch step time: 124.39100289344788\n",
      "Epoch 10, total loss 144190965.984375, total predictions 14700, avg loss 9808.909251 2022-06-16 13:27:38.157850\n",
      "Saving model. Best loss: 9808.909250637755\n",
      "Number epochs: 11 epoch step time: 124.49170303344727\n",
      "Number epochs: 12 epoch step time: 130.04326796531677\n",
      "Saving model. Best loss: 9278.291878188775\n",
      "Number epochs: 13 epoch step time: 127.55358576774597\n",
      "Number epochs: 14 epoch step time: 139.21106100082397\n",
      "Number epochs: 15 epoch step time: 139.0414490699768\n",
      "Epoch 15, total loss 141621142.859375, total predictions 14700, avg loss 9634.091351 2022-06-16 13:38:38.499635\n",
      "Number epochs: 16 epoch step time: 141.4626088142395\n",
      "Number epochs: 17 epoch step time: 149.90662121772766\n",
      "Number epochs: 18 epoch step time: 149.92094206809998\n",
      "Number epochs: 19 epoch step time: 140.02305722236633\n",
      "Number epochs: 20 epoch step time: 141.24217915534973\n",
      "Epoch 20, total loss 139185158.000000, total predictions 14700, avg loss 9468.378095 2022-06-16 13:50:41.055826\n",
      "Number epochs: 21 epoch step time: 144.5085289478302\n",
      "Number epochs: 22 epoch step time: 151.07144784927368\n",
      "Number epochs: 23 epoch step time: 153.00692296028137\n",
      "Number epochs: 24 epoch step time: 146.53069806098938\n",
      "Number epochs: 25 epoch step time: 150.66964197158813\n",
      "Epoch 25, total loss 149901540.183594, total predictions 14700, avg loss 10197.383686 2022-06-16 14:03:06.843878\n",
      "Number epochs: 26 epoch step time: 163.03526997566223\n",
      "Number epochs: 27 epoch step time: 153.3127989768982\n",
      "Number epochs: 28 epoch step time: 146.66845083236694\n",
      "Number epochs: 29 epoch step time: 155.07784295082092\n",
      "Number epochs: 30 epoch step time: 160.215313911438\n",
      "Epoch 30, total loss 118783919.089844, total predictions 14700, avg loss 8080.538714 2022-06-16 14:16:05.155395\n",
      "Saving model. Best loss: 8080.538713594813\n",
      "Number epochs: 31 epoch step time: 151.95181488990784\n",
      "Number epochs: 32 epoch step time: 150.48915195465088\n",
      "Number epochs: 33 epoch step time: 131.74257898330688\n",
      "Number epochs: 34 epoch step time: 126.84981298446655\n",
      "Number epochs: 35 epoch step time: 137.39674496650696\n",
      "Epoch 35, total loss 160231559.558594, total predictions 14700, avg loss 10900.106092 2022-06-16 14:27:43.589369\n",
      "Number epochs: 36 epoch step time: 138.95857691764832\n",
      "Number epochs: 37 epoch step time: 139.50891995429993\n",
      "Number epochs: 38 epoch step time: 159.41947960853577\n",
      "Number epochs: 39 epoch step time: 190.98524498939514\n",
      "Number epochs: 40 epoch step time: 122.2351598739624\n",
      "Epoch 40, total loss 141775723.183594, total predictions 14700, avg loss 9644.607019 2022-06-16 14:40:14.697568\n",
      "Number epochs: 41 epoch step time: 122.14331579208374\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d552f9c26806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 seq_len=200)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ee2a891fa3fe>\u001b[0m in \u001b[0;36mtrain_i24_model\u001b[0;34m(timeseries_dict, n_epoch, model, seq_len)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beginning training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mfinish_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished training, total time: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinish_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbegin_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_2022/Anti-Flow/Detectors/Deep_Learning/AutoEncoders/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_X, model_file_name, n_epoch, seq_len)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mtrain_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_ls\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_tot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_2022/Anti-Flow/Detectors/Deep_Learning/AutoEncoders/utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anti_flow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_2022/Anti-Flow/Detectors/Deep_Learning/AutoEncoders/cnn_lstm_ae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anti_flow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_2022/Anti-Flow/Detectors/Deep_Learning/AutoEncoders/cnn_lstm_ae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0m_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anti_flow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/anti_flow/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_i24_model(timeseries_dict_training,\n",
    "                n_epoch=60,\n",
    "                model=None,\n",
    "                seq_len=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anti_flow",
   "language": "python",
   "name": "anti_flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
